{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## TESTING"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import redditcleaner\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim import corpora, models\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import pyLDAvis.gensim_models as gensimvis\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                body\n",
      "0  We've known about the specter of censorship as...\n",
      "1  Hello I just started reading about TRP theorie...\n",
      "2  **CorporateLand: Don’t Kill the Job v. Quiet Q...\n",
      "3  **Schrödinger’s Girlfriend**\\n\\n*“Girls are ne...\n",
      "4  Hola amigos!! This is my current gameplan.  Pl...\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "df =  pd.read_csv(\"redpill_sample_500.csv\",\n",
    "                  usecols=[\"body\"],\n",
    "                  na_filter=\"NaN\",\n",
    "                  na_values=\"NaN\").dropna()\n",
    "\n",
    "df[\"body\"].dropna(inplace=True)\n",
    "#df['post_preprocessed'] = df.apply(preprocess_text).str.lower()\n",
    "#\n",
    "#print('lemming...')\n",
    "#nltk.download('wordnet')\n",
    "#lemmatizer = WordNetLemmatizer()\n",
    "#df['post_final'] = df['post_preprocessed'].apply(lambda post: lemmatize_words(post, lemmatizer))\n",
    "#\n",
    "#print('remove stopwors...')\n",
    "#\n",
    "#nltk.download('stopwords')\n",
    "#swords = set(stopwords.words('english'))\n",
    "#\n",
    "#df['post_final'] = df['post_preprocessed'].apply(lambda post: remove_stopwords(post, swords))\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "0      We've known about the specter of censorship as...\n1      Hello I just started reading about TRP theorie...\n2      **CorporateLand: Don’t Kill the Job v. Quiet Q...\n3      **Schrödinger’s Girlfriend**\\n\\n*“Girls are ne...\n4      Hola amigos!! This is my current gameplan.  Pl...\n                             ...                        \n351    Recently my mate and I started a small daily h...\n352    Listen when you’ve been on the road as long as...\n353    Day 7 of no fap, 6 months off weed, day 4 of h...\n354    This is from our elder statesman and a founder...\n355    **The Importance of Manliness.**\\n\\nIt’s impor...\nName: body, Length: 348, dtype: object"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"body\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "text_cleaned = redditcleaner.clean(df[\"body\"][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'Hello I just started reading about TRP theories. I am still at the early chapters of the Handbook and cannot quite pin where this situation stands: I met a girl at a festival, we exchanged instagrams and now I am seeing that 80% of her stories are heavy drinking and partying. I tease her about that for a while and yesterday I asked her \"I can\\'t remember, but are you studying something at the moment?\" My intention was to spin this around college parties and invite myself to one. She answered with \"No, I don\\'t study anything\", but some time has passed and I was out of the mood for texting and into the mood for going to bed, so I just decided I will answer in the morning. This morning I just left her on \"seen\" and texted nothing back. I realized that I don\\'t feel like continuing the topic and really can\\'t bother with coming up with something witty to say. I think I will just text her in a few days about some other topic. How would you classify the current situation? I think it is qualification/rapport break, but I also want to hear more experienced opinion, to check if I am understand correctly what I read in the Handbook.'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaned"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "0      We've known about the specter of censorship as...\n1      Hello I just started reading about TRP theorie...\n2      **CorporateLand: Don’t Kill the Job v. Quiet Q...\n3      **Schrödinger’s Girlfriend**\\n\\n*“Girls are ne...\n4      Hola amigos!! This is my current gameplan.  Pl...\n                             ...                        \n351    Recently my mate and I started a small daily h...\n352    Listen when you’ve been on the road as long as...\n353    Day 7 of no fap, 6 months off weed, day 4 of h...\n354    This is from our elder statesman and a founder...\n355    **The Importance of Manliness.**\\n\\nIt’s impor...\nName: body, Length: 348, dtype: object"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"body\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "cleaned_text = []\n",
    "for row in range(len(df[\"body\"])):\n",
    "    try:\n",
    "        cleaned_text.append(redditcleaner.clean(df['body'][row]))\n",
    "    except TypeError:\n",
    "        continue\n",
    "    except KeyError:\n",
    "        continue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "340"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "clean_df = pd.DataFrame(cleaned_text, columns=[\"body\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: DeprecationWarning: invalid escape sequence \\S\n",
      "<>:16: DeprecationWarning: invalid escape sequence \\s\n",
      "<>:12: DeprecationWarning: invalid escape sequence \\S\n",
      "<>:16: DeprecationWarning: invalid escape sequence \\s\n",
      "<>:12: DeprecationWarning: invalid escape sequence \\S\n",
      "<>:16: DeprecationWarning: invalid escape sequence \\s\n",
      "/var/folders/59/t9r6dbl91y18h_j87198fnl40000gn/T/ipykernel_10241/3997932686.py:12: DeprecationWarning: invalid escape sequence \\S\n",
      "  email_pattern = re.compile('\\S*@\\S*\\s?')\n",
      "/var/folders/59/t9r6dbl91y18h_j87198fnl40000gn/T/ipykernel_10241/3997932686.py:16: DeprecationWarning: invalid escape sequence \\s\n",
      "  return re.sub('\\s+', ' ', text)\n"
     ]
    }
   ],
   "source": [
    "def remove_urls(text):\n",
    "    \" removes urls\"\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def remove_html(text):\n",
    "    \" removes html tags\"\n",
    "    html_pattern = re.compile('')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "def remove_emails(text):\n",
    "    email_pattern = re.compile('\\S*@\\S*\\s?')\n",
    "    return email_pattern.sub(r'', text)\n",
    "\n",
    "def remove_new_line(text):\n",
    "    return re.sub('\\s+', ' ', text)\n",
    "\n",
    "def remove_non_alpha(text):\n",
    "    return re.sub(\"[^A-Za-z]+\", ' ', str(text))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    #t = remove_urls(text)\n",
    "    t = remove_html(text)\n",
    "    #t = remove_emails(t)\n",
    "    t = remove_new_line(t)\n",
    "    t = remove_non_alpha(t)\n",
    "    return t\n",
    "\n",
    "def lemmatize_words(text, lemmatizer):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "def remove_stopwords(text, stopwords):\n",
    "    return \" \".join([word for word in str(text).split() if word not in stopwords])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemming...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/tugberk/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove stopwors...\n",
      "                                                body  \\\n",
      "0  We've known about the specter of censorship as...   \n",
      "1  Hello I just started reading about TRP theorie...   \n",
      "2  CorporateLand: Don’t Kill the Job v. Quiet Qui...   \n",
      "3  Schrödinger’s Girlfriend “Girls are never sing...   \n",
      "4  Hola amigos This is my current gameplan. Pleas...   \n",
      "\n",
      "                                   post_preprocessed  \\\n",
      "0  we ve known about the specter of censorship as...   \n",
      "1  hello i just started reading about trp theorie...   \n",
      "2  corporateland don t kill the job v quiet quitt...   \n",
      "3  schr dinger s girlfriend girls are never singl...   \n",
      "4  hola amigos this is my current gameplan please...   \n",
      "\n",
      "                                          post_final  \n",
      "0  known specter censorship red pill censorship f...  \n",
      "1  started reading trp theories early chapters ha...  \n",
      "2  corporateland kill job v quiet quitting two di...  \n",
      "3  schr dinger girlfriend single relationships sa...  \n",
      "4  hola amigos current gameplan please note newbi...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tugberk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "\n",
    "clean_df['post_preprocessed'] = clean_df['body'].apply(preprocess_text).str.lower()\n",
    "\n",
    "print('lemming...')\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "clean_df['post_final'] = clean_df['post_preprocessed'].apply(lambda post: lemmatize_words(post, lemmatizer))\n",
    "\n",
    "print('remove stopwors...')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "swords = stopwords.words('english')\n",
    "swords.extend(['from', 'woman',\n",
    "               'women','men',\n",
    "               'man','like',\n",
    "               'even','go','one',\n",
    "               'topic','morning','something',\n",
    "               'girl','girls', 'guy', 'give',\n",
    "               'would','things',\n",
    "               'know','really',\n",
    "               'never','hello',\n",
    "               'first','every','lot','much','make',\n",
    "               'want','life','good','x',\n",
    "               'people','going','getting','saying',\n",
    "               'day', 'get',\n",
    "               'say','way',\n",
    "               'guys', 'think',\n",
    "               'feel','also',\n",
    "               'see', 'need', 'thing',\n",
    "               'b', 'many',\n",
    "               'take','let',\n",
    "               'still', 'fuck',\n",
    "               'could','may',\n",
    "               'said', 'back', 'better', 'always', 'right',\n",
    "               'time', 'shit','around', 'fucking', 'work',\n",
    "               'sexual', 'got', 'years', 'post', 'point',\n",
    "               'self', 'world',\n",
    "               'ever','trying', 'talking',\n",
    "               'long', 'year', 'tell',\n",
    "               'another', 'someone', 'look',\n",
    "               'everything', 'anything', 'nothing',\n",
    "               'find', 'enough', 'actually',\n",
    "               'keep', 'well', 'best', 'number',\n",
    "               'sex', 'game', 'mind',\n",
    "               'talk', 'new', 'next', 'love'])\n",
    "swords =set(swords)\n",
    "clean_df['post_final'] = clean_df['post_preprocessed'].apply(lambda post: remove_stopwords(post, swords))\n",
    "print(clean_df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  body  \\\n44   I started off thinking trp was about girls and...   \n113  Casey Anthony epitomized something that I coul...   \n289  Most modern men (men is a strong word, maybe f...   \n198  Hello brothers, I’m not sure any of you may re...   \n\n                                     post_preprocessed  \\\n44   i started off thinking trp was about girls and...   \n113  casey anthony epitomized something that i coul...   \n289  most modern men men is a strong word maybe fem...   \n198  hello brothers i m not sure any of you may rem...   \n\n                                            post_final  \n44   started thinking trp pussy far beyond honestly...  \n113  casey anthony epitomized quite put finger sat ...  \n289  modern strong word maybe femboy accurate addic...  \n198  brothers sure remember story almost two since ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>body</th>\n      <th>post_preprocessed</th>\n      <th>post_final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>44</th>\n      <td>I started off thinking trp was about girls and...</td>\n      <td>i started off thinking trp was about girls and...</td>\n      <td>started thinking trp pussy far beyond honestly...</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>Casey Anthony epitomized something that I coul...</td>\n      <td>casey anthony epitomized something that i coul...</td>\n      <td>casey anthony epitomized quite put finger sat ...</td>\n    </tr>\n    <tr>\n      <th>289</th>\n      <td>Most modern men (men is a strong word, maybe f...</td>\n      <td>most modern men men is a strong word maybe fem...</td>\n      <td>modern strong word maybe femboy accurate addic...</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>Hello brothers, I’m not sure any of you may re...</td>\n      <td>hello brothers i m not sure any of you may rem...</td>\n      <td>brothers sure remember story almost two since ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.sample(4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "outputs": [],
   "source": [
    "posts = [x.split(' ') for x in clean_df['post_final']]\n",
    "#p2 = []\n",
    "#for i in range(len(posts)):\n",
    " #   p2.append(posts[posts[i] not in ['women','men','man','like','even','go','one', 'topic','morning','something']])\n",
    "id2word = corpora.Dictionary(posts)\n",
    "corpus_tf = [id2word.doc2bow(text) for text in posts]\n",
    "#print(corpus_tf[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus_tf)\n",
    "corpus_tfidf = tfidf[corpus_tf]\n",
    "#print(corpus_tfidf[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1136559547404297\n"
     ]
    }
   ],
   "source": [
    "model = LdaMulticore(corpus=corpus_tf,id2word = id2word, num_topics = 5,\n",
    "                    chunksize=50,\n",
    "                     random_state = 0)\n",
    "\n",
    "coherence = CoherenceModel(model = model, texts = posts, dictionary = id2word, coherence = 'u_mass')\n",
    "\n",
    "print(coherence.get_coherence())\n",
    "#print(model.show_topics())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0 \n",
      " [('approach', 0.00256927), ('high', 0.0019090173), ('night', 0.0018843431), ('frame', 0.0018474186), ('social', 0.0018260332), ('different', 0.0018228294), ('wants', 0.0017581327), ('alpha', 0.0017472613), ('might', 0.0017390577), ('little', 0.0017377133)]\n",
      "topic 1 \n",
      " [('try', 0.0020712262), ('without', 0.0019180439), ('social', 0.0018719806), ('us', 0.0018109387), ('relationship', 0.0017857852), ('partners', 0.001703858), ('else', 0.0016711933), ('alpha', 0.001654076), ('red', 0.0016463625), ('since', 0.0016174719)]\n",
      "topic 2 \n",
      " [('us', 0.0024020176), ('try', 0.0023717063), ('red', 0.002290104), ('approach', 0.002251057), ('start', 0.0021032104), ('pill', 0.0018654057), ('use', 0.0018206816), ('come', 0.0018175311), ('relationship', 0.0018103085), ('friends', 0.001782004)]\n",
      "topic 3 \n",
      " [('made', 0.00214781), ('attractive', 0.0021055061), ('red', 0.0019165752), ('money', 0.0019107821), ('pill', 0.0019084745), ('wanted', 0.0018895182), ('approach', 0.0018783741), ('making', 0.0018472611), ('must', 0.0018304784), ('friends', 0.0017959399)]\n",
      "topic 4 \n",
      " [('alpha', 0.0022357882), ('relationship', 0.0020831823), ('end', 0.0020738197), ('pill', 0.0020317226), ('friend', 0.0018706205), ('makes', 0.0018437824), ('money', 0.0018378191), ('hard', 0.0018240936), ('making', 0.0017719999), ('start', 0.0017515356)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"topic {} \\n\".format(i),model.show_topic(topicid=i,topn=10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "outputs": [
    {
     "data": {
      "text/plain": "     dominant_topic  perc_contribution  \\\n130               2              0.996   \n261               0              0.995   \n230               4              0.996   \n209               4              0.793   \n333               0              0.970   \n150               2              0.999   \n219               2              0.512   \n153               2              0.497   \n306               2              0.975   \n290               4              0.997   \n55                2              0.994   \n182               1              0.926   \n249               2              0.991   \n138               3              0.938   \n134               3              0.996   \n137               4              0.997   \n321               2              0.997   \n9                 4              0.966   \n258               3              0.752   \n20                0              0.989   \n\n                                        topic_keywords  \\\n130  us, try, red, approach, start, pill, use, come...   \n261  approach, high, night, frame, social, differen...   \n230  alpha, relationship, end, pill, friend, makes,...   \n209  alpha, relationship, end, pill, friend, makes,...   \n333  approach, high, night, frame, social, differen...   \n150  us, try, red, approach, start, pill, use, come...   \n219  us, try, red, approach, start, pill, use, come...   \n153  us, try, red, approach, start, pill, use, come...   \n306  us, try, red, approach, start, pill, use, come...   \n290  alpha, relationship, end, pill, friend, makes,...   \n55   us, try, red, approach, start, pill, use, come...   \n182  try, without, social, us, relationship, partne...   \n249  us, try, red, approach, start, pill, use, come...   \n138  made, attractive, red, money, pill, wanted, ap...   \n134  made, attractive, red, money, pill, wanted, ap...   \n137  alpha, relationship, end, pill, friend, makes,...   \n321  us, try, red, approach, start, pill, use, come...   \n9    alpha, relationship, end, pill, friend, makes,...   \n258  made, attractive, red, money, pill, wanted, ap...   \n20   approach, high, night, frame, social, differen...   \n\n                                                  post  \n130  Let me start from the begining. this post is a...  \n261  It's been 3 years since my last TRP post. Figu...  \n230  So, I'll keep this brief. There's probably a b...  \n209  Good afternoon TRP. Today I want to cover some...  \n333  There's a saying in sales and Internet Marketi...  \n150   Intro: You’ve been working out for a while, w...  \n219  &x200B; Attraction. This single concept gets m...  \n153  Bear with me through the intro, it's needed fo...  \n306  I had posted earlier in the asktrp subreddit a...  \n290  My calculus teacher was ahead of his time: > T...  \n55   “No one can change your life but you.” I read ...  \n182  Older Men And Younger Women, Part IV: There ar...  \n249  Inspiration for this essay: In my previous pos...  \n138  TL;DR: Orbiter told girl I was being unfaithfu...  \n134  You all may have heard about an old saying whi...  \n137  The Will Smith-Chris Rock panzy fest from Sund...  \n321  Lazy, unfocused, unmotivated, binge eating, mi...  \n9    The traditional dynamic was that women offered...  \n258  How many times have you heard women saying, I ...  \n20   This is a text that was mailed to me by a ther...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dominant_topic</th>\n      <th>perc_contribution</th>\n      <th>topic_keywords</th>\n      <th>post</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>130</th>\n      <td>2</td>\n      <td>0.996</td>\n      <td>us, try, red, approach, start, pill, use, come...</td>\n      <td>Let me start from the begining. this post is a...</td>\n    </tr>\n    <tr>\n      <th>261</th>\n      <td>0</td>\n      <td>0.995</td>\n      <td>approach, high, night, frame, social, differen...</td>\n      <td>It's been 3 years since my last TRP post. Figu...</td>\n    </tr>\n    <tr>\n      <th>230</th>\n      <td>4</td>\n      <td>0.996</td>\n      <td>alpha, relationship, end, pill, friend, makes,...</td>\n      <td>So, I'll keep this brief. There's probably a b...</td>\n    </tr>\n    <tr>\n      <th>209</th>\n      <td>4</td>\n      <td>0.793</td>\n      <td>alpha, relationship, end, pill, friend, makes,...</td>\n      <td>Good afternoon TRP. Today I want to cover some...</td>\n    </tr>\n    <tr>\n      <th>333</th>\n      <td>0</td>\n      <td>0.970</td>\n      <td>approach, high, night, frame, social, differen...</td>\n      <td>There's a saying in sales and Internet Marketi...</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>2</td>\n      <td>0.999</td>\n      <td>us, try, red, approach, start, pill, use, come...</td>\n      <td>Intro: You’ve been working out for a while, w...</td>\n    </tr>\n    <tr>\n      <th>219</th>\n      <td>2</td>\n      <td>0.512</td>\n      <td>us, try, red, approach, start, pill, use, come...</td>\n      <td>&amp;x200B; Attraction. This single concept gets m...</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>2</td>\n      <td>0.497</td>\n      <td>us, try, red, approach, start, pill, use, come...</td>\n      <td>Bear with me through the intro, it's needed fo...</td>\n    </tr>\n    <tr>\n      <th>306</th>\n      <td>2</td>\n      <td>0.975</td>\n      <td>us, try, red, approach, start, pill, use, come...</td>\n      <td>I had posted earlier in the asktrp subreddit a...</td>\n    </tr>\n    <tr>\n      <th>290</th>\n      <td>4</td>\n      <td>0.997</td>\n      <td>alpha, relationship, end, pill, friend, makes,...</td>\n      <td>My calculus teacher was ahead of his time: &gt; T...</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>2</td>\n      <td>0.994</td>\n      <td>us, try, red, approach, start, pill, use, come...</td>\n      <td>“No one can change your life but you.” I read ...</td>\n    </tr>\n    <tr>\n      <th>182</th>\n      <td>1</td>\n      <td>0.926</td>\n      <td>try, without, social, us, relationship, partne...</td>\n      <td>Older Men And Younger Women, Part IV: There ar...</td>\n    </tr>\n    <tr>\n      <th>249</th>\n      <td>2</td>\n      <td>0.991</td>\n      <td>us, try, red, approach, start, pill, use, come...</td>\n      <td>Inspiration for this essay: In my previous pos...</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>3</td>\n      <td>0.938</td>\n      <td>made, attractive, red, money, pill, wanted, ap...</td>\n      <td>TL;DR: Orbiter told girl I was being unfaithfu...</td>\n    </tr>\n    <tr>\n      <th>134</th>\n      <td>3</td>\n      <td>0.996</td>\n      <td>made, attractive, red, money, pill, wanted, ap...</td>\n      <td>You all may have heard about an old saying whi...</td>\n    </tr>\n    <tr>\n      <th>137</th>\n      <td>4</td>\n      <td>0.997</td>\n      <td>alpha, relationship, end, pill, friend, makes,...</td>\n      <td>The Will Smith-Chris Rock panzy fest from Sund...</td>\n    </tr>\n    <tr>\n      <th>321</th>\n      <td>2</td>\n      <td>0.997</td>\n      <td>us, try, red, approach, start, pill, use, come...</td>\n      <td>Lazy, unfocused, unmotivated, binge eating, mi...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4</td>\n      <td>0.966</td>\n      <td>alpha, relationship, end, pill, friend, makes,...</td>\n      <td>The traditional dynamic was that women offered...</td>\n    </tr>\n    <tr>\n      <th>258</th>\n      <td>3</td>\n      <td>0.752</td>\n      <td>made, attractive, red, money, pill, wanted, ap...</td>\n      <td>How many times have you heard women saying, I ...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0</td>\n      <td>0.989</td>\n      <td>approach, high, night, frame, social, differen...</td>\n      <td>This is a text that was mailed to me by a ther...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = {'dominant_topic':[], 'perc_contribution':[], 'topic_keywords':[]}\n",
    "\n",
    "for i, row in enumerate(model[corpus_tf]):\n",
    "    #print(i)\n",
    "    row = sorted(row, key=lambda x: x[1], reverse=True)\n",
    "    #print(row)\n",
    "    for j, (topic_num, prop_topic) in enumerate(row):\n",
    "        wp = model.show_topic(topic_num)\n",
    "        topic_keywords = \", \".join([word for word, prop in wp])\n",
    "        data_dict['dominant_topic'].append(int(topic_num))\n",
    "        data_dict['perc_contribution'].append(round(prop_topic, 3))\n",
    "        data_dict['topic_keywords'].append(topic_keywords)\n",
    "        #print(topic_keywords)\n",
    "        break\n",
    "\n",
    "df_topics = pd.DataFrame(data_dict)\n",
    "\n",
    "contents = pd.Series(posts)\n",
    "\n",
    "df_topics['post'] = clean_df['body']\n",
    "df_topics.sample(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0 \n",
      " 284    A lot has been written on the topic of No Nut ...\n",
      "251    One of my favourite TRP contributors is u/Wouj...\n",
      "31     In today's society the most important thing to...\n",
      "98     1. You are gonna be timid and fearful in your ...\n",
      "122    This is a breakdown of a post from the Stoicis...\n",
      "Name: post, dtype: object \n",
      "\n",
      "topic 1 \n",
      " 110    For an introduction, have been a follower, rea...\n",
      "11     Through EEO/AA, men have been bleeding their t...\n",
      "259    Gonna be a lenhy post so sit down, relax and g...\n",
      "46     TL;DR: Left my girl, we grew apart. My \"RP'd f...\n",
      "277    Diwali (the festival of lights, if you're inte...\n",
      "Name: post, dtype: object \n",
      "\n",
      "topic 2 \n",
      " 231    When listening to Red Pill content, a lot of t...\n",
      "301    Now that I've got your attention, humor me and...\n",
      "184    Put Yourself First. Why Being an Asshole is a ...\n",
      "268    There has been far too many noobers around the...\n",
      "311    There are a lot of men who find the Red Pill b...\n",
      "Name: post, dtype: object \n",
      "\n",
      "topic 3 \n",
      " 217    A guy in this sub asked; >How do you cope with...\n",
      "169    To start this off, I have known a lot of men w...\n",
      "28     It’s been a year since I started cold approach...\n",
      "2      CorporateLand: Don’t Kill the Job v. Quiet Qui...\n",
      "320    Here is some text from a book I am working on....\n",
      "Name: post, dtype: object \n",
      "\n",
      "topic 4 \n",
      " 218    The things we teach here must be learned the h...\n",
      "206    I wrote a novella about a young mans self impr...\n",
      "339    I'm 23 years old, been a part of the community...\n",
      "315    I've written many posts on this subreddit and ...\n",
      "117    The \"Not You\" rule can apply to any guy, but m...\n",
      "Name: post, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"topic {} \\n\".format(i),df_topics[df_topics[\"dominant_topic\"] == i][\"post\"].sample(5), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}